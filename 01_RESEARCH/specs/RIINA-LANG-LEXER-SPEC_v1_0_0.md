â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•      â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â–ˆâ–ˆâ•‘â•šâ•â•â•â•â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘
   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
   â•šâ•â•   â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•      â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â•
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    LEXICAL STRUCTURE SPECIFICATION
                           VERSION 1.0.0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SESSION: A-R01
TITLE: TERAS-LANG Lexical Structure Specification
VERSION: 1.0.0
DATE: 2026-01-01
STATUS: AUTHORITATIVE
PROTOCOL: TERAS ULTRA KIASU (Zero Trust, Zero Gap, Zero Shortcuts, Zero Lazy)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCUMENT METADATA                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Document ID      : TERAS-LANG-LEXER-SPEC                                    â”‚
â”‚ Version          : 1.0.0                                                    â”‚
â”‚ Date             : 2026-01-01                                               â”‚
â”‚ Session          : A-R01 (Research Session 1 of 100)                        â”‚
â”‚ Author           : Claude (Anthropic)                                       â”‚
â”‚ Status           : AUTHORITATIVE                                            â”‚
â”‚ Supersedes       : None (First Version)                                     â”‚
â”‚ Line Count       : 2,700+ lines                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Related Documents:                                                          â”‚
â”‚   - CTSS_v1_0_1.md (Core Type System Specification)                         â”‚
â”‚   - teras-lang-foundation-v0_3_1.md (Decisions D1-D47)                      â”‚
â”‚   - TERAS_ULTIMATE_STRATEGIC_MASTER_DOCUMENT_v1_0_0.md                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCUMENT PURPOSE                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ This document provides the COMPLETE and AUTHORITATIVE specification for     â”‚
â”‚ the lexical structure of TERAS-LANG. Every lexical element is defined with  â”‚
â”‚ NO GAPS, NO AMBIGUITY, and NO PLACEHOLDERS.                                 â”‚
â”‚                                                                             â”‚
â”‚ PROTOCOL REQUIREMENTS:                                                      â”‚
â”‚   âœ“ Zero Trust: Every rule explicitly stated                               â”‚
â”‚   âœ“ Zero Gap: No undefined behavior or edge cases                          â”‚
â”‚   âœ“ Zero Shortcuts: Complete formal definitions                            â”‚
â”‚   âœ“ Zero Lazy: Exhaustive enumeration of all elements                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PART 1: CHARACTER ENCODING SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 1.1 UTF-8 Encoding Requirement

```
RULE UTF8-001: Source File Encoding
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All TERAS-LANG source files MUST be encoded in UTF-8.
No other encoding is accepted.

REJECTED ENCODINGS:
  - UTF-16 (LE or BE)
  - UTF-32 (LE or BE)
  - ISO-8859-1 (Latin-1)
  - ISO-8859-15 (Latin-9)
  - Windows-1252
  - GB2312, GBK, GB18030
  - Big5
  - Shift_JIS, EUC-JP
  - KS X 1001, EUC-KR
  - Any other encoding not UTF-8

RATIONALE: UTF-8 is the universal encoding for modern software.
Single encoding eliminates transcoding errors and security issues.
```

## 1.2 Valid UTF-8 Byte Sequences

```
RULE UTF8-002: Valid Byte Sequences
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

One-byte sequences (U+0000 to U+007F):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Byte 1  â”‚ 0xxxxxxx (0x00-0x7F)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Range   â”‚ 0x00-0x7F (128 code points)                                     â”‚
â”‚ Unicode â”‚ U+0000 to U+007F                                                â”‚
â”‚ Content â”‚ ASCII characters                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Two-byte sequences (U+0080 to U+07FF):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Byte 1  â”‚ 110xxxxx (0xC2-0xDF)                                            â”‚
â”‚ Byte 2  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Range   â”‚ 0xC2 0x80 to 0xDF 0xBF                                          â”‚
â”‚ Unicode â”‚ U+0080 to U+07FF                                                â”‚
â”‚ Content â”‚ Latin Extended, Greek, Cyrillic, Hebrew, Arabic, etc.           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTE: 0xC0 and 0xC1 are NEVER valid first bytes (would create overlong
encodings of ASCII characters).

Three-byte sequences (U+0800 to U+FFFF):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Byte 1  â”‚ 1110xxxx (0xE0-0xEF)                                            â”‚
â”‚ Byte 2  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”‚ Byte 3  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Special â”‚ If Byte 1 = 0xE0, Byte 2 MUST be 0xA0-0xBF (not 0x80-0x9F)     â”‚
â”‚ Special â”‚ If Byte 1 = 0xED, Byte 2 MUST be 0x80-0x9F (not 0xA0-0xBF)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Range   â”‚ 0xE0 0xA0 0x80 to 0xEF 0xBF 0xBF (excluding surrogates)        â”‚
â”‚ Unicode â”‚ U+0800 to U+FFFF (excluding U+D800-U+DFFF)                      â”‚
â”‚ Content â”‚ CJK, Thai, Georgian, Ethiopic, BMP symbols, etc.               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SURROGATE EXCLUSION: The range U+D800-U+DFFF (UTF-16 surrogates) is
INVALID in UTF-8 and MUST be rejected. These would be encoded as:
  - 0xED 0xA0 0x80 to 0xED 0xBF 0xBF
This range MUST produce a lexer error.

Four-byte sequences (U+10000 to U+10FFFF):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Byte 1  â”‚ 11110xxx (0xF0-0xF4)                                            â”‚
â”‚ Byte 2  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”‚ Byte 3  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”‚ Byte 4  â”‚ 10xxxxxx (0x80-0xBF)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Special â”‚ If Byte 1 = 0xF0, Byte 2 MUST be 0x90-0xBF (not 0x80-0x8F)     â”‚
â”‚ Special â”‚ If Byte 1 = 0xF4, Byte 2 MUST be 0x80-0x8F (not 0x90-0xBF)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Range   â”‚ 0xF0 0x90 0x80 0x80 to 0xF4 0x8F 0xBF 0xBF                      â”‚
â”‚ Unicode â”‚ U+10000 to U+10FFFF                                             â”‚
â”‚ Content â”‚ Emoji, historic scripts, musical symbols, etc.                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTE: 0xF5-0xFF are NEVER valid first bytes (would exceed U+10FFFF).
```

## 1.3 Invalid Byte Sequences

```
RULE UTF8-003: Invalid Byte Sequences
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The following byte sequences are INVALID and MUST be rejected:

1. OVERLONG ENCODINGS
   - 0xC0, 0xC1 as first byte (overlong ASCII)
   - 0xE0 0x80-0x9F (overlong two-byte)
   - 0xF0 0x80-0x8F (overlong three-byte)
   
   Example: 0xC0 0x80 is overlong NUL (should be 0x00)
   Example: 0xE0 0x80 0x80 is overlong NUL (should be 0x00)
   
   ERROR: "Overlong UTF-8 encoding detected"

2. SURROGATE CODE POINTS
   - 0xED 0xA0-0xBF followed by any continuation (U+D800-U+DFFF)
   
   ERROR: "UTF-16 surrogate code point in UTF-8"

3. CODE POINTS BEYOND U+10FFFF
   - 0xF4 0x90-0xBF or higher
   - 0xF5-0xFF as first byte
   
   ERROR: "Code point exceeds Unicode maximum U+10FFFF"

4. UNEXPECTED CONTINUATION BYTES
   - 0x80-0xBF appearing without a valid leading byte
   
   ERROR: "Unexpected UTF-8 continuation byte"

5. TRUNCATED SEQUENCES
   - Multi-byte sequence that ends prematurely
   - Leading byte not followed by enough continuation bytes
   
   ERROR: "Truncated UTF-8 sequence"

6. INVALID LEADING BYTES
   - 0xFE, 0xFF (never valid in UTF-8)
   
   ERROR: "Invalid UTF-8 leading byte"
```

## 1.4 Byte Order Mark (BOM) Handling

```
RULE UTF8-004: BOM Rejection
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

POLICY: TERAS-LANG REJECTS files beginning with a UTF-8 BOM.

BOM BYTES: 0xEF 0xBB 0xBF

If these three bytes are detected at the start of a source file:
  1. Report error: "UTF-8 BOM detected; TERAS-LANG source files must not 
     contain a BOM"
  2. Halt lexing immediately
  3. Exit with error status

RATIONALE:
  - BOM is unnecessary for UTF-8 (byte order is unambiguous)
  - BOM causes problems with Unix shebang lines
  - BOM is invisible and causes subtle bugs
  - Modern tools do not require BOM
  - Google, Mozilla, and W3C recommend against UTF-8 BOM

REMEDIATION: Remove BOM using: sed -i '1s/^\xEF\xBB\xBF//' file.teras
```

## 1.5 Unicode Normalization

```
RULE UTF8-005: NFC Normalization Requirement
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All identifiers MUST be in Unicode Normalization Form C (NFC).

NORMALIZATION FORMS:
  - NFD: Canonical Decomposition
  - NFC: Canonical Decomposition + Canonical Composition
  - NFKD: Compatibility Decomposition
  - NFKC: Compatibility Decomposition + Canonical Composition

TERAS-LANG REQUIRES: NFC (Composed form)

EXAMPLE:
  NFD: e + Ì  (U+0065 U+0301) - decomposed
  NFC: Ã©     (U+00E9) - composed
  
Both represent the same character, but TERAS-LANG requires NFC.

BEHAVIOR:
  1. If identifier is not in NFC:
     - Emit WARNING: "Identifier not in NFC form; normalizing"
     - Normalize to NFC before processing
  2. Two identifiers that normalize to the same NFC string are IDENTICAL
  3. Comparison always uses NFC-normalized forms

IMPLEMENTATION:
  fn normalize_identifier(s: &str) -> String {
      unicode_normalization::UnicodeNormalization::nfc(s).collect()
  }
  
  fn compare_identifiers(a: &str, b: &str) -> bool {
      normalize_identifier(a) == normalize_identifier(b)
  }
```

## 1.6 Confusable Character Detection

```
RULE UTF8-006: Confusable Character Detection
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TERAS-LANG implements security measures against confusable characters.

1. HOMOGLYPH DETECTION
   Characters that look similar but have different code points:
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Latin    â”‚ Cyrillic â”‚ Description                                     â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ A U+0041 â”‚ Ð U+0410 â”‚ Capital A vs Cyrillic A                         â”‚
   â”‚ B U+0042 â”‚ Ð’ U+0412 â”‚ Capital B vs Cyrillic Ve                        â”‚
   â”‚ C U+0043 â”‚ Ð¡ U+0421 â”‚ Capital C vs Cyrillic Es                        â”‚
   â”‚ E U+0045 â”‚ Ð• U+0415 â”‚ Capital E vs Cyrillic Ie                        â”‚
   â”‚ H U+0048 â”‚ Ð U+041D â”‚ Capital H vs Cyrillic En                        â”‚
   â”‚ K U+004B â”‚ Ðš U+041A â”‚ Capital K vs Cyrillic Ka                        â”‚
   â”‚ M U+004D â”‚ Ðœ U+041C â”‚ Capital M vs Cyrillic Em                        â”‚
   â”‚ O U+004F â”‚ Ðž U+041E â”‚ Capital O vs Cyrillic O                         â”‚
   â”‚ P U+0050 â”‚ Ð  U+0420 â”‚ Capital P vs Cyrillic Er                        â”‚
   â”‚ T U+0054 â”‚ Ð¢ U+0422 â”‚ Capital T vs Cyrillic Te                        â”‚
   â”‚ X U+0058 â”‚ Ð¥ U+0425 â”‚ Capital X vs Cyrillic Ha                        â”‚
   â”‚ a U+0061 â”‚ Ð° U+0430 â”‚ Small a vs Cyrillic a                           â”‚
   â”‚ c U+0063 â”‚ Ñ U+0441 â”‚ Small c vs Cyrillic es                          â”‚
   â”‚ e U+0065 â”‚ Ðµ U+0435 â”‚ Small e vs Cyrillic ie                          â”‚
   â”‚ o U+006F â”‚ Ð¾ U+043E â”‚ Small o vs Cyrillic o                           â”‚
   â”‚ p U+0070 â”‚ Ñ€ U+0440 â”‚ Small p vs Cyrillic er                          â”‚
   â”‚ x U+0078 â”‚ Ñ… U+0445 â”‚ Small x vs Cyrillic ha                          â”‚
   â”‚ y U+0079 â”‚ Ñƒ U+0443 â”‚ Small y vs Cyrillic u                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   WARNING: "Identifier contains characters confusable with ASCII"

2. MIXED-SCRIPT DETECTION
   Identifiers mixing multiple scripts receive warnings:
   
   ALLOWED COMBINATIONS:
   - Latin + Common (punctuation, digits)
   - Any single script + Common
   
   WARNING COMBINATIONS:
   - Latin + Cyrillic
   - Latin + Greek (except standard mathematical symbols)
   - Any unexpected script mixture
   
   WARNING: "Mixed-script identifier detected"

3. ZERO-WIDTH CHARACTER DETECTION
   The following are REJECTED in identifiers:
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Code Point â”‚ Name                                                      â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ U+200B     â”‚ ZERO WIDTH SPACE                                          â”‚
   â”‚ U+200C     â”‚ ZERO WIDTH NON-JOINER (except valid use in certain langs) â”‚
   â”‚ U+200D     â”‚ ZERO WIDTH JOINER (except valid use in certain langs)     â”‚
   â”‚ U+2060     â”‚ WORD JOINER                                               â”‚
   â”‚ U+FEFF     â”‚ ZERO WIDTH NO-BREAK SPACE (BOM)                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   ERROR: "Zero-width character in identifier"

4. BIDIRECTIONAL OVERRIDE DETECTION
   The following are REJECTED everywhere in source:
   
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Code Point â”‚ Name                                                      â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ U+202A     â”‚ LEFT-TO-RIGHT EMBEDDING                                   â”‚
   â”‚ U+202B     â”‚ RIGHT-TO-LEFT EMBEDDING                                   â”‚
   â”‚ U+202C     â”‚ POP DIRECTIONAL FORMATTING                                â”‚
   â”‚ U+202D     â”‚ LEFT-TO-RIGHT OVERRIDE                                    â”‚
   â”‚ U+202E     â”‚ RIGHT-TO-LEFT OVERRIDE                                    â”‚
   â”‚ U+2066     â”‚ LEFT-TO-RIGHT ISOLATE                                     â”‚
   â”‚ U+2067     â”‚ RIGHT-TO-LEFT ISOLATE                                     â”‚
   â”‚ U+2068     â”‚ FIRST STRONG ISOLATE                                      â”‚
   â”‚ U+2069     â”‚ POP DIRECTIONAL ISOLATE                                   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
   ERROR: "Bidirectional control character detected (potential Trojan Source)"
```

## 1.7 Line Ending Normalization

```
RULE UTF8-007: Line Ending Normalization
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All line endings are normalized to LF (U+000A) during lexing.

NORMALIZATION RULES:
  CR LF (0x0D 0x0A) â†’ LF (0x0A)   Windows line ending
  CR    (0x0D)      â†’ LF (0x0A)   Old Mac line ending
  LF    (0x0A)      â†’ LF (0x0A)   Unix line ending (unchanged)

REJECTED LINE ENDINGS:
  U+0085 NEXT LINE (NEL)           â†’ ERROR
  U+2028 LINE SEPARATOR            â†’ ERROR
  U+2029 PARAGRAPH SEPARATOR       â†’ ERROR

ERROR: "Non-standard line ending character U+XXXX; use LF, CR, or CRLF"

LINE COUNTING:
  - Lines are numbered starting at 1
  - Each normalized LF increments line number
  - Line number is used for error reporting
```

## 1.8 Source File Constraints

```
RULE UTF8-008: Source File Constraints
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MAXIMUM FILE SIZE: 16 MiB (16,777,216 bytes)
  - Files exceeding this limit produce an error
  - ERROR: "Source file exceeds maximum size of 16 MiB"

MAXIMUM LINE LENGTH: 10,000 Unicode scalar values
  - Lines exceeding this limit produce a warning
  - WARNING: "Line exceeds 10,000 characters"

MAXIMUM TOKENS: 10,000,000 tokens per file
  - Files exceeding this limit produce an error
  - ERROR: "Source file exceeds maximum token count"

RATIONALE:
  - Prevents denial-of-service via large files
  - Ensures reasonable compilation times
  - Catches likely errors (binary files, generated code)
```

## 1.9 Position Tracking

```
RULE UTF8-009: Position Tracking
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The lexer tracks source positions for error reporting.

POSITION STRUCTURE:
  struct Position {
      byte_offset: u32,  // 0-based byte offset from file start
      line: u32,         // 1-based line number
      column: u32,       // 1-based column in Unicode scalar values
  }

BYTE OFFSET:
  - Counts bytes, not characters
  - 0 is the first byte of the file
  - Useful for extracting source text

LINE NUMBER:
  - Counts logical lines after normalization
  - 1 is the first line
  - Incremented after each normalized LF

COLUMN NUMBER:
  - Counts Unicode scalar values, not bytes or grapheme clusters
  - 1 is the first column
  - Reset to 1 after each line increment
  - Tab (U+0009) advances to next multiple of 8 for display purposes

SPAN STRUCTURE:
  struct Span {
      start: Position,
      end: Position,
      file_id: FileId,
  }
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PART 2: WHITESPACE AND LAYOUT SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 2.1 Horizontal Whitespace Characters

```
RULE SPACE-001: Horizontal Whitespace
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The following characters are recognized as horizontal whitespace:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Point â”‚ Name                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ U+0009     â”‚ CHARACTER TABULATION (Tab)                                    â”‚
â”‚ U+0020     â”‚ SPACE                                                         â”‚
â”‚ U+00A0     â”‚ NO-BREAK SPACE                                                â”‚
â”‚ U+1680     â”‚ OGHAM SPACE MARK                                              â”‚
â”‚ U+2000     â”‚ EN QUAD                                                       â”‚
â”‚ U+2001     â”‚ EM QUAD                                                       â”‚
â”‚ U+2002     â”‚ EN SPACE                                                      â”‚
â”‚ U+2003     â”‚ EM SPACE                                                      â”‚
â”‚ U+2004     â”‚ THREE-PER-EM SPACE                                            â”‚
â”‚ U+2005     â”‚ FOUR-PER-EM SPACE                                             â”‚
â”‚ U+2006     â”‚ SIX-PER-EM SPACE                                              â”‚
â”‚ U+2007     â”‚ FIGURE SPACE                                                  â”‚
â”‚ U+2008     â”‚ PUNCTUATION SPACE                                             â”‚
â”‚ U+2009     â”‚ THIN SPACE                                                    â”‚
â”‚ U+200A     â”‚ HAIR SPACE                                                    â”‚
â”‚ U+202F     â”‚ NARROW NO-BREAK SPACE                                         â”‚
â”‚ U+205F     â”‚ MEDIUM MATHEMATICAL SPACE                                     â”‚
â”‚ U+3000     â”‚ IDEOGRAPHIC SPACE                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

All of these are treated as token separators.
None carry semantic meaning.
```

## 2.2 Vertical Whitespace Characters

```
RULE SPACE-002: Vertical Whitespace
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The following characters are recognized as vertical whitespace:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Point â”‚ Name                                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ U+000A     â”‚ LINE FEED (LF)                                                â”‚
â”‚ U+000B     â”‚ LINE TABULATION (VT)                                          â”‚
â”‚ U+000C     â”‚ FORM FEED (FF)                                                â”‚
â”‚ U+000D     â”‚ CARRIAGE RETURN (CR)                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

As per UTF8-007, CR and CRLF are normalized to LF.
VT and FF are treated as line terminators but do NOT increment line count.
```

## 2.3 Excluded Whitespace Characters

```
RULE SPACE-003: Excluded Characters
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

The following characters are NOT treated as whitespace:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Code Point â”‚ Name                           â”‚ Treatment                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ U+0085     â”‚ NEXT LINE (NEL)                â”‚ ERROR                        â”‚
â”‚ U+200B     â”‚ ZERO WIDTH SPACE               â”‚ ERROR                        â”‚
â”‚ U+2028     â”‚ LINE SEPARATOR                 â”‚ ERROR                        â”‚
â”‚ U+2029     â”‚ PARAGRAPH SEPARATOR            â”‚ ERROR                        â”‚
â”‚ U+FEFF     â”‚ ZERO WIDTH NO-BREAK SPACE      â”‚ ERROR (BOM)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

These characters produce errors when encountered in source code.
```

## 2.4 Indentation Semantics

```
RULE SPACE-004: Indentation Has No Semantic Meaning
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Unlike Python, TERAS-LANG indentation is purely cosmetic.
Block structure is determined by braces { }, not indentation.

EXAMPLE (valid code despite inconsistent indentation):
  fn example() {
  let x = 1;
      let y = 2;
   let z = 3;
  }

STYLE RECOMMENDATION:
  - Use 4 spaces for indentation
  - Do not mix tabs and spaces
  - Be consistent within a file
```

## 2.5 Tab Handling

```
RULE SPACE-005: Tab Handling
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Tabs (U+0009) are valid whitespace but spaces are preferred.

TAB WIDTH: 8 columns (for display purposes)

BEHAVIOR:
  - Tabs separate tokens like spaces
  - Tab advances column to next multiple of 8 for error display
  - WARNING (optional): "Tab character found; consider using spaces"
  - Enable with --warn-tabs flag

RATIONALE: Different editors display tabs differently, causing
confusion. Spaces ensure consistent appearance.
```

## 2.6 Line Continuation

```
RULE SPACE-006: No Line Continuation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

TERAS-LANG does NOT support explicit line continuation.

REJECTED: backslash-newline continuation (like C, Python)
  let x = 1 + \    // NOT SUPPORTED
          2;

INSTEAD: Use delimiters for natural continuation:

IMPLICIT CONTINUATION within delimiters:
  - Parentheses: (...)
  - Brackets: [...]
  - Braces: {...}
  - Angle brackets: <...> (in type contexts)

EXAMPLE (natural continuation):
  let result = calculate(
      argument_one,
      argument_two,
      argument_three,
  );
  
  let array = [
      1, 2, 3,
      4, 5, 6,
  ];
```

## 2.7 Token Separation Rules

```
RULE SPACE-007: Token Separation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

REQUIRED SEPARATION (whitespace or comment needed):
  - Two consecutive identifiers: foo bar (not foobar)
  - Identifier followed by keyword: x if (not xif)
  - Keyword followed by identifier: if x (not ifx)
  - Two consecutive keywords: pub fn (not pubfn)
  - Number followed by identifier (except suffixes): 42 foo (not 42foo)

NO SEPARATION REQUIRED:
  - Operator followed by operator: ++ (if valid)
  - Punctuation followed by punctuation: () []
  - Identifier followed by punctuation: foo( foo[
  - Punctuation followed by identifier: (foo [bar
  - Number with suffix: 42i32 (suffix attaches)

MAXIMAL MUNCH RULE:
  The lexer always consumes the longest valid token.
  
  EXAMPLE: "+++" â†’ ++ + (not + ++)
  EXAMPLE: ">>=" â†’ >>= (not > >=)
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        PART 3: COMMENTS SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 3.1 Line Comments

```
RULE COMMENT-001: Line Comments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SYNTAX: // followed by any characters until end of line

GRAMMAR:
  line_comment = "//" (!newline any_char)* newline?

EXAMPLES:
  // This is a line comment
  let x = 42; // Inline comment
  //////////  Also a valid comment

BEHAVIOR:
  - Comment extends to newline or EOF
  - Newline is NOT part of comment content
  - Line comment cannot span multiple lines
  - No nesting (// inside // is just content)
```

## 3.2 Block Comments

```
RULE COMMENT-002: Block Comments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SYNTAX: /* followed by content followed by */

GRAMMAR:
  block_comment = "/*" block_content "*/"
  block_content = (block_comment | !"*/" any_char)*

NESTING: Block comments NEST in TERAS-LANG.

EXAMPLES:
  /* Simple block comment */
  
  /* Multi-line
     block comment */
  
  /* Outer /* Nested */ comment */
  
  /*
   * Common style
   * with asterisks
   */

NESTING BEHAVIOR:
  - Each /* increases nesting depth
  - Each */ decreases nesting depth
  - Comment ends when depth returns to 0
  
  EXAMPLE:
    /* depth=1 /* depth=2 */ depth=1 */ depth=0
    
  RATIONALE: Nesting allows commenting out code that contains comments.
  This matches Rust's behavior.
```

## 3.3 Documentation Comments

```
RULE COMMENT-003: Documentation Comments
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

OUTER DOC COMMENTS (document the following item):

Line form:   /// content
Block form:  /** content */

INNER DOC COMMENTS (document the enclosing item):

Line form:   //! content
Block form:  /*! content */

EXAMPLES:

/// This documents the function below
fn documented_function() {}

/** 
 * This also documents the function below
 */
fn another_function() {}

mod my_module {
    //! This documents the module itself
    
    /*! 
     * This also documents the module
     */
}

SPECIAL CASES:

//// (four slashes) is a REGULAR comment, NOT a doc comment
//!  is inner doc comment
///  is outer doc comment
/**/ is empty block comment, NOT a doc comment
/** */ is a doc comment (space inside)

ATTACHMENT RULES:
  - Outer doc comments attach to the immediately following declaration
  - Inner doc comments attach to the enclosing declaration
  - Multiple doc comments concatenate with newlines
  - Whitespace between doc comments is preserved
```

## 3.4 Comment Content Rules

```
RULE COMMENT-004: Comment Content Restrictions
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

WARNINGS for suspicious content:

1. NUL CHARACTER (U+0000)
   WARNING: "NUL character in comment"
   
2. BIDIRECTIONAL OVERRIDES
   WARNING: "Bidirectional control in comment (potential Trojan Source)"
   Characters: U+202A-U+202E, U+2066-U+2069
   
3. ZERO-WIDTH CHARACTERS
   WARNING: "Zero-width character in comment"
   Characters: U+200B, U+200C, U+200D, U+FEFF
   
4. TODO/FIXME MARKERS (optional, with --warn-todos)
   WARNING: "TODO marker in comment"
   WARNING: "FIXME marker in comment"
   WARNING: "HACK marker in comment"
   WARNING: "XXX marker in comment"
```

## 3.5 Markdown in Doc Comments

```
RULE COMMENT-005: Doc Comment Markdown Support
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Doc comments support Markdown formatting:

HEADERS:
  /// # Main Header
  /// ## Sub Header

EMPHASIS:
  /// **bold** and *italic* and `code`

CODE BLOCKS:
  /// ```
  /// let x = 42;
  /// ```
  
  /// ```teras
  /// fn example() {}
  /// ```

LISTS:
  /// - Item 1
  /// - Item 2
  ///   - Nested item

LINKS:
  /// [Link text](url)
  /// [Type reference][`SomeType`]

SPECIAL SECTIONS:
  /// # Examples
  /// # Panics
  /// # Errors
  /// # Safety
  /// # See Also
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PART 4: IDENTIFIERS SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 4.1 Identifier Grammar

```
RULE IDENT-001: Identifier Syntax
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

GRAMMAR:
  identifier     = ident_start ident_continue*
  raw_identifier = "r#" identifier
  ident_start    = XID_Start | "_"
  ident_continue = XID_Continue | "_"

XID_Start (Unicode derived property):
  - Lu: Letter, Uppercase (1,791 characters)
  - Ll: Letter, Lowercase (2,227 characters)
  - Lt: Letter, Titlecase (31 characters)
  - Lm: Letter, Modifier (260 characters)
  - Lo: Letter, Other (127,333 characters)
  - Nl: Number, Letter (236 characters)
  - Plus underscore (_)

XID_Continue:
  - All XID_Start characters, plus:
  - Mn: Mark, Nonspacing (1,839 characters)
  - Mc: Mark, Spacing Combining (445 characters)
  - Nd: Number, Decimal Digit (650 characters)
  - Pc: Punctuation, Connector (10 characters)

EXAMPLES (valid):
  foo, bar, _private, camelCase, PascalCase, CONSTANT
  cafÃ©, naÃ¯ve, æ—¥æœ¬èªž, ä¸­æ–‡, Î•Î»Î»Î·Î½Î¹ÎºÎ¬, ×¢×‘×¨×™×ª
  Î±, Î², Î³, Î´, Ï€, Î£
  simpan, tukar, rahsia, lindungi (Malay)

EXAMPLES (invalid):
  0foo     (starts with digit)
  @foo     (@ not in XID_Start)
  foo@bar  (@ not in XID_Continue)
  -foo     (- not in XID_Start)
```

## 4.2 Raw Identifiers

```
RULE IDENT-002: Raw Identifiers
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

SYNTAX: r# followed by any identifier (including keywords)

PURPOSE: Allow keywords to be used as identifiers when necessary.

EXAMPLES:
  r#fn      â†’ identifier "fn"
  r#let     â†’ identifier "let"
  r#match   â†’ identifier "match"
  r#type    â†’ identifier "type"
  r#self    â†’ identifier "self"
  r#Self    â†’ identifier "Self"

USE CASES:
  - FFI with languages using different keywords
  - Serialization/deserialization with keyword field names
  - Code generation
  - Macro-generated code

RESTRICTIONS:
  - r# prefix cannot be used with _ alone: r#_ is INVALID
  - r# prefix cannot be doubled: r#r#foo is INVALID
  - r# does not apply to reserved keywords: r#abstract works
```

## 4.3 Identifier Constraints

```
RULE IDENT-003: Identifier Length and Content
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MAXIMUM LENGTH: 1,024 Unicode scalar values
  ERROR: "Identifier exceeds maximum length of 1024 characters"

NFC NORMALIZATION: Required (see UTF8-005)
  - Identifiers are normalized before comparison
  - cafÃ© (composed) and cafÃ© (decomposed) are the same identifier

CASE SENSITIVITY: TERAS-LANG identifiers are CASE SENSITIVE
  - foo â‰  Foo â‰  FOO â‰  fOO
  - All are distinct identifiers

UNDERSCORE RULES:
  - Single underscore (_) is a PLACEHOLDER PATTERN, not an identifier
  - _foo is a valid identifier (conventional: unused variable)
  - __foo is valid but RESERVED (warning: internal use)
  - ___foo is valid but strongly discouraged
  - foo_ is valid (no special meaning)
  - foo__ is valid (no special meaning)
```

## 4.4 Malay Identifier Examples

```
RULE IDENT-004: Malay Language Identifiers (D46)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Per Decision D46, TERAS products and standard library use Malay names.
All these identifiers use Latin characters and are fully supported.

CORE OPERATIONS:
  simpan          (save/store)
  muatkan         (load)
  hapus           (delete)
  tukar           (convert)
  senarai         (list)
  peta            (map)
  tapis           (filter)
  kira            (calculate)
  semak           (check)
  sahkan          (validate)

SECURITY TERMS:
  rahsia          (secret)
  awam            (public)
  sulit           (confidential)
  tercemar        (tainted)
  bersih          (clean/sanitized)
  lindungi        (protect)
  jejak           (trace/audit)

PRODUCT NAMES:
  menara          (tower - MENARA mobile security)
  gapura          (gateway - GAPURA WAF)
  zirah           (armor - ZIRAH EDR)
  benteng         (fortress - BENTENG eKYC)
  sandi           (cipher - SANDI digital signature)

COMPONENT NAMES:
  nadi            (pulse - health monitoring)
  saraf           (nerve - neural network)
  tulang          (bone - framework)
  kulit           (skin - interface)
  jantung         (heart - core)
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        PART 5: KEYWORDS SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 5.1 Control Flow Keywords (9)

```
RULE KW-001: Control Flow Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if        â”‚ Conditional branching                                          â”‚
â”‚ else      â”‚ Alternative branch for if                                      â”‚
â”‚ match     â”‚ Pattern matching expression                                    â”‚
â”‚ loop      â”‚ Infinite loop                                                  â”‚
â”‚ while     â”‚ Conditional loop                                               â”‚
â”‚ for       â”‚ Iterator loop                                                  â”‚
â”‚ break     â”‚ Exit from loop with optional value                             â”‚
â”‚ continue  â”‚ Skip to next loop iteration                                    â”‚
â”‚ return    â”‚ Return from function with optional value                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.2 Declaration Keywords (12)

```
RULE KW-002: Declaration Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ fn        â”‚ Function declaration                                           â”‚
â”‚ let       â”‚ Variable binding                                               â”‚
â”‚ mut       â”‚ Mutable binding modifier                                       â”‚
â”‚ const     â”‚ Compile-time constant                                          â”‚
â”‚ static    â”‚ Static variable (lifetime 'static)                             â”‚
â”‚ type      â”‚ Type alias declaration                                         â”‚
â”‚ struct    â”‚ Structure type declaration                                     â”‚
â”‚ enum      â”‚ Enumeration type declaration                                   â”‚
â”‚ union     â”‚ Union type declaration (unsafe)                                â”‚
â”‚ trait     â”‚ Trait (interface) declaration                                  â”‚
â”‚ impl      â”‚ Implementation block                                           â”‚
â”‚ mod       â”‚ Module declaration                                             â”‚
â”‚ use       â”‚ Import declaration                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.3 Type Keywords (5)

```
RULE KW-003: Type Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Self      â”‚ Type of current impl block                                     â”‚
â”‚ self      â”‚ Current instance reference                                     â”‚
â”‚ where     â”‚ Type constraint clause                                         â”‚
â”‚ as        â”‚ Type casting / renaming                                        â”‚
â”‚ dyn       â”‚ Dynamic dispatch marker                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.4 Modifier Keywords (10)

```
RULE KW-004: Modifier Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ pub       â”‚ Public visibility                                              â”‚
â”‚ priv      â”‚ Private visibility (explicit)                                  â”‚
â”‚ unsafe    â”‚ Unsafe block/function marker                                   â”‚
â”‚ async     â”‚ Asynchronous function/block                                    â”‚
â”‚ await     â”‚ Await asynchronous result                                      â”‚
â”‚ move      â”‚ Move capture in closures                                       â”‚
â”‚ ref       â”‚ Reference pattern binding                                      â”‚
â”‚ extern    â”‚ External linkage                                               â”‚
â”‚ crate     â”‚ Crate-level visibility/reference                               â”‚
â”‚ super     â”‚ Parent module reference                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.5 Effect System Keywords (5)

```
RULE KW-005: Effect System Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ effect    â”‚ Effect type declaration                                        â”‚
â”‚ handle    â”‚ Effect handler block                                           â”‚
â”‚ perform   â”‚ Perform effect operation                                       â”‚
â”‚ resume    â”‚ Resume from effect handler                                     â”‚
â”‚ abort     â”‚ Abort effect handling                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.6 Security Keywords (8)

```
RULE KW-006: Security Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword         â”‚ Description                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ secret          â”‚ Secret type qualifier                                    â”‚
â”‚ tainted         â”‚ Tainted data marker                                      â”‚
â”‚ sanitized       â”‚ Sanitized data marker                                    â”‚
â”‚ declassify      â”‚ Declassification operation                               â”‚
â”‚ label           â”‚ Security label annotation                                â”‚
â”‚ ct              â”‚ Constant-time execution marker                           â”‚
â”‚ zeroize         â”‚ Secure memory zeroing                                    â”‚
â”‚ speculation_safeâ”‚ Speculation safety marker                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.7 Linear Type Keywords (4)

```
RULE KW-007: Linear Type Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ linear    â”‚ Linear type (must use exactly once)                            â”‚
â”‚ affine    â”‚ Affine type (use at most once)                                 â”‚
â”‚ once      â”‚ Single-use qualifier                                           â”‚
â”‚ drop      â”‚ Explicit drop/destructor                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.8 Memory Model Keywords (7)

```
RULE KW-008: Memory Model Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ atomic    â”‚ Atomic type/operation                                          â”‚
â”‚ fence     â”‚ Memory fence                                                   â”‚
â”‚ acquire   â”‚ Acquire memory ordering                                        â”‚
â”‚ release   â”‚ Release memory ordering                                        â”‚
â”‚ seqcst    â”‚ Sequentially consistent ordering                               â”‚
â”‚ relaxed   â”‚ Relaxed memory ordering                                        â”‚
â”‚ acqrel    â”‚ Acquire-release ordering                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.9 Session Type Keywords (6)

```
RULE KW-009: Session Type Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ session   â”‚ Session type declaration                                       â”‚
â”‚ send      â”‚ Send operation in session                                      â”‚
â”‚ recv      â”‚ Receive operation in session                                   â”‚
â”‚ select    â”‚ Select branch in session                                       â”‚
â”‚ branch    â”‚ Branch point in session                                        â”‚
â”‚ end       â”‚ Session termination                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.10 Capability Keywords (2)

```
RULE KW-010: Capability Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword    â”‚ Description                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ capability â”‚ Capability type declaration                                   â”‚
â”‚ revoke     â”‚ Capability revocation                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.11 Product Keywords (1)

```
RULE KW-011: Product Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ product   â”‚ Product type annotation (MENARA, GAPURA, etc.)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.12 Boolean/Special Keywords (3)

```
RULE KW-012: Boolean and Special Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword   â”‚ Description                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ true      â”‚ Boolean true literal                                           â”‚
â”‚ false     â”‚ Boolean false literal                                          â”‚
â”‚ combined  â”‚ Combined security label                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.13 Reserved Keywords (26)

```
RULE KW-013: Reserved Keywords
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

These keywords are RESERVED for future use. Using them produces an error.

STANDARD RESERVED (13):
  abstract, become, box, do, final, macro, override, priv,
  try, typeof, unsized, virtual, yield

TERAS-SPECIFIC RESERVED (13):
  audit, compliance, encrypt, integrity, isolate, policy,
  prove, refine, require, ensure, invariant, trusted, verify

ERROR: "Keyword 'X' is reserved for future use"

NOTE: Reserved keywords CAN be used with r# prefix: r#abstract
```

## 5.14 Complete Keyword Count

```
RULE KW-014: Keyword Totals
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category                    â”‚ Count                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Control Flow                â”‚ 9                                          â”‚
â”‚ Declaration                 â”‚ 12                                         â”‚
â”‚ Type                        â”‚ 5                                          â”‚
â”‚ Modifier                    â”‚ 10                                         â”‚
â”‚ Effect System               â”‚ 5                                          â”‚
â”‚ Security                    â”‚ 8                                          â”‚
â”‚ Linear Types                â”‚ 4                                          â”‚
â”‚ Memory Model                â”‚ 7                                          â”‚
â”‚ Session Types               â”‚ 6                                          â”‚
â”‚ Capability                  â”‚ 2                                          â”‚
â”‚ Product                     â”‚ 1                                          â”‚
â”‚ Boolean/Special             â”‚ 3                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ACTIVE KEYWORDS             â”‚ 72                                         â”‚
â”‚ Reserved Keywords           â”‚ 26                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL KEYWORDS              â”‚ 98                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  PART 6: OPERATORS AND PUNCTUATION SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 6.1 Arithmetic Operators

```
RULE OP-001: Arithmetic Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ +      â”‚ Plus             â”‚ 13         â”‚ Left         â”‚ Addition        â”‚
â”‚ -      â”‚ Minus            â”‚ 13         â”‚ Left         â”‚ Subtraction     â”‚
â”‚ *      â”‚ Star             â”‚ 14         â”‚ Left         â”‚ Multiplication  â”‚
â”‚ /      â”‚ Slash            â”‚ 14         â”‚ Left         â”‚ Division        â”‚
â”‚ %      â”‚ Percent          â”‚ 14         â”‚ Left         â”‚ Remainder       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - + and - are also unary operators (precedence 16, right)
  - * is also dereference (precedence 16, right)
  - Integer division truncates toward zero
  - Division by zero: panic at runtime
```

## 6.2 Comparison Operators

```
RULE OP-002: Comparison Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ==     â”‚ Equals           â”‚ 7          â”‚ None         â”‚ Equality        â”‚
â”‚ !=     â”‚ NotEquals        â”‚ 7          â”‚ None         â”‚ Inequality      â”‚
â”‚ <      â”‚ Less             â”‚ 8          â”‚ None         â”‚ Less than       â”‚
â”‚ >      â”‚ Greater          â”‚ 8          â”‚ None         â”‚ Greater than    â”‚
â”‚ <=     â”‚ LessEq           â”‚ 8          â”‚ None         â”‚ Less or equal   â”‚
â”‚ >=     â”‚ GreaterEq        â”‚ 8          â”‚ None         â”‚ Greater or equalâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - Non-associative: a < b < c is INVALID (unlike Python)
  - Must use: a < b && b < c
  - < and > also used for generics (parser disambiguates)
```

## 6.3 Logical Operators

```
RULE OP-003: Logical Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ &&     â”‚ And              â”‚ 6          â”‚ Left         â”‚ Logical AND     â”‚
â”‚ ||     â”‚ Or               â”‚ 5          â”‚ Left         â”‚ Logical OR      â”‚
â”‚ !      â”‚ Not              â”‚ 16         â”‚ Right        â”‚ Logical NOT     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - && and || are SHORT-CIRCUIT operators
  - && evaluates right only if left is true
  - || evaluates right only if left is false
  - ! is unary prefix operator
```

## 6.4 Bitwise Operators

```
RULE OP-004: Bitwise Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ &      â”‚ Ampersand        â”‚ 11         â”‚ Left         â”‚ Bitwise AND     â”‚
â”‚ |      â”‚ Pipe             â”‚ 9          â”‚ Left         â”‚ Bitwise OR      â”‚
â”‚ ^      â”‚ Caret            â”‚ 10         â”‚ Left         â”‚ Bitwise XOR     â”‚
â”‚ <<     â”‚ Shl              â”‚ 12         â”‚ Left         â”‚ Left shift      â”‚
â”‚ >>     â”‚ Shr              â”‚ 12         â”‚ Left         â”‚ Right shift     â”‚
â”‚ ~      â”‚ Tilde            â”‚ 16         â”‚ Right        â”‚ Bitwise NOT     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - & is also reference operator (prefix)
  - | is also closure parameter delimiter
  - >> is also part of nested generics: Vec<Vec<T>>
```

## 6.5 Assignment Operators

```
RULE OP-005: Assignment Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ =      â”‚ Assign           â”‚ 3          â”‚ Right        â”‚ Assignment      â”‚
â”‚ +=     â”‚ AddAssign        â”‚ 3          â”‚ Right        â”‚ Add and assign  â”‚
â”‚ -=     â”‚ SubAssign        â”‚ 3          â”‚ Right        â”‚ Sub and assign  â”‚
â”‚ *=     â”‚ MulAssign        â”‚ 3          â”‚ Right        â”‚ Mul and assign  â”‚
â”‚ /=     â”‚ DivAssign        â”‚ 3          â”‚ Right        â”‚ Div and assign  â”‚
â”‚ %=     â”‚ RemAssign        â”‚ 3          â”‚ Right        â”‚ Rem and assign  â”‚
â”‚ &=     â”‚ AndAssign        â”‚ 3          â”‚ Right        â”‚ AND and assign  â”‚
â”‚ |=     â”‚ OrAssign         â”‚ 3          â”‚ Right        â”‚ OR and assign   â”‚
â”‚ ^=     â”‚ XorAssign        â”‚ 3          â”‚ Right        â”‚ XOR and assign  â”‚
â”‚ <<=    â”‚ ShlAssign        â”‚ 3          â”‚ Right        â”‚ Shl and assign  â”‚
â”‚ >>=    â”‚ ShrAssign        â”‚ 3          â”‚ Right        â”‚ Shr and assign  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - Assignment is an expression (returns ())
  - Right associative: a = b = c means a = (b = c)
```

## 6.6 Range Operators

```
RULE OP-006: Range Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ..     â”‚ Range            â”‚ 4          â”‚ None         â”‚ Exclusive range â”‚
â”‚ ..=    â”‚ RangeInclusive   â”‚ 4          â”‚ None         â”‚ Inclusive range â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

FORMS:
  a..b    Range from a (inclusive) to b (exclusive)
  a..     Range from a to infinity
  ..b     Range from start to b (exclusive)
  ..=b    Range from start to b (inclusive)
  a..=b   Range from a (inclusive) to b (inclusive)
  ..      Full range

NOTES:
  - .. is also struct update syntax: Foo { x, ..other }
  - Non-associative: a..b..c is INVALID
```

## 6.7 Other Operators

```
RULE OP-007: Other Operators
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Precedence â”‚ Associativityâ”‚ Description     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ?      â”‚ Try              â”‚ 17         â”‚ Postfix      â”‚ Error propagate â”‚
â”‚ ->     â”‚ Arrow            â”‚ N/A        â”‚ N/A          â”‚ Return type     â”‚
â”‚ =>     â”‚ FatArrow         â”‚ N/A        â”‚ N/A          â”‚ Match arm       â”‚
â”‚ ::     â”‚ PathSep          â”‚ 18         â”‚ Left         â”‚ Path separator  â”‚
â”‚ .      â”‚ Dot              â”‚ 18         â”‚ Left         â”‚ Field/method    â”‚
â”‚ @      â”‚ At               â”‚ N/A        â”‚ N/A          â”‚ Pattern binding â”‚
â”‚ &mut   â”‚ MutRef           â”‚ 16         â”‚ Right        â”‚ Mutable ref     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 6.8 Punctuation

```
RULE OP-008: Punctuation
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Symbol â”‚ Name             â”‚ Description                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ (      â”‚ OpenParen        â”‚ Open parenthesis                             â”‚
â”‚ )      â”‚ CloseParen       â”‚ Close parenthesis                            â”‚
â”‚ [      â”‚ OpenBracket      â”‚ Open square bracket                          â”‚
â”‚ ]      â”‚ CloseBracket     â”‚ Close square bracket                         â”‚
â”‚ {      â”‚ OpenBrace        â”‚ Open curly brace                             â”‚
â”‚ }      â”‚ CloseBrace       â”‚ Close curly brace                            â”‚
â”‚ <      â”‚ Lt               â”‚ Less than / Open angle                       â”‚
â”‚ >      â”‚ Gt               â”‚ Greater than / Close angle                   â”‚
â”‚ ,      â”‚ Comma            â”‚ Separator                                    â”‚
â”‚ ;      â”‚ Semicolon        â”‚ Statement terminator                         â”‚
â”‚ :      â”‚ Colon            â”‚ Type annotation / Label                      â”‚
â”‚ '      â”‚ Apostrophe       â”‚ Lifetime / Character literal                 â”‚
â”‚ "      â”‚ Quote            â”‚ String literal delimiter                     â”‚
â”‚ #      â”‚ Hash             â”‚ Attribute marker                             â”‚
â”‚ $      â”‚ Dollar           â”‚ Macro variable                               â”‚
â”‚ _      â”‚ Underscore       â”‚ Placeholder pattern                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 6.9 Complete Precedence Table

```
RULE OP-009: Complete Precedence Table
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prec â”‚ Operators                               â”‚ Associativity â”‚ Category â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 18   â”‚ . :: () [] (postfix)                    â”‚ Left          â”‚ Path     â”‚
â”‚ 17   â”‚ ? (postfix)                             â”‚ Left          â”‚ Try      â”‚
â”‚ 16   â”‚ - ! * & &mut ~ (prefix)                 â”‚ Right         â”‚ Unary    â”‚
â”‚ 15   â”‚ as                                      â”‚ Left          â”‚ Cast     â”‚
â”‚ 14   â”‚ * / %                                   â”‚ Left          â”‚ Factor   â”‚
â”‚ 13   â”‚ + -                                     â”‚ Left          â”‚ Term     â”‚
â”‚ 12   â”‚ << >>                                   â”‚ Left          â”‚ Shift    â”‚
â”‚ 11   â”‚ &                                       â”‚ Left          â”‚ BitAnd   â”‚
â”‚ 10   â”‚ ^                                       â”‚ Left          â”‚ BitXor   â”‚
â”‚ 9    â”‚ |                                       â”‚ Left          â”‚ BitOr    â”‚
â”‚ 8    â”‚ < > <= >=                               â”‚ None          â”‚ Compare  â”‚
â”‚ 7    â”‚ == !=                                   â”‚ None          â”‚ Equality â”‚
â”‚ 6    â”‚ &&                                      â”‚ Left          â”‚ And      â”‚
â”‚ 5    â”‚ ||                                      â”‚ Left          â”‚ Or       â”‚
â”‚ 4    â”‚ .. ..=                                  â”‚ None          â”‚ Range    â”‚
â”‚ 3    â”‚ = += -= *= /= %= &= |= ^= <<= >>=       â”‚ Right         â”‚ Assign   â”‚
â”‚ 2    â”‚ return break continue                   â”‚ Right         â”‚ Control  â”‚
â”‚ 1    â”‚ Closure expressions                     â”‚ N/A           â”‚ Closure  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        PART 7: LITERALS SPECIFICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 7.1 Integer Literals

```
RULE LIT-001: Integer Literal Syntax
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

DECIMAL:
  Format: [0-9][0-9_]*
  Examples: 0, 1, 42, 1_000, 999_999_999

HEXADECIMAL:
  Format: 0x[0-9a-fA-F][0-9a-fA-F_]*
  Examples: 0x0, 0xFF, 0xDEAD_BEEF, 0x1234_5678

OCTAL:
  Format: 0o[0-7][0-7_]*
  Examples: 0o0, 0o7, 0o755, 0o777

BINARY:
  Format: 0b[01][01_]*
  Examples: 0b0, 0b1, 0b1010, 0b1111_0000

UNDERSCORES:
  - Allowed anywhere after prefix (0x, 0o, 0b) or first digit
  - Purely cosmetic, ignored in value
  - 1_000 = 1000, 0xFF_FF = 0xFFFF

LEADING ZEROS:
  - Allowed in decimal: 007 = 7
  - Required for octal: 0o7 (not just 07)
```

## 7.2 Integer Type Suffixes

```
RULE LIT-002: Integer Type Suffixes
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Suffix  â”‚ Description                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ i8      â”‚ Signed 8-bit integer (-128 to 127)                              â”‚
â”‚ i16     â”‚ Signed 16-bit integer (-32768 to 32767)                         â”‚
â”‚ i32     â”‚ Signed 32-bit integer                                           â”‚
â”‚ i64     â”‚ Signed 64-bit integer                                           â”‚
â”‚ i128    â”‚ Signed 128-bit integer                                          â”‚
â”‚ isize   â”‚ Signed pointer-sized integer                                    â”‚
â”‚ u8      â”‚ Unsigned 8-bit integer (0 to 255)                               â”‚
â”‚ u16     â”‚ Unsigned 16-bit integer (0 to 65535)                            â”‚
â”‚ u32     â”‚ Unsigned 32-bit integer                                         â”‚
â”‚ u64     â”‚ Unsigned 64-bit integer                                         â”‚
â”‚ u128    â”‚ Unsigned 128-bit integer                                        â”‚
â”‚ usize   â”‚ Unsigned pointer-sized integer                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DEFAULT (no suffix): i32

EXAMPLES:
  42i8, 1000u32, 0xFFu8, 0b1010i64
```

## 7.3 Floating-Point Literals

```
RULE LIT-003: Floating-Point Literal Syntax
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

BASIC FORMAT:
  [0-9][0-9_]* "." [0-9][0-9_]*

SCIENTIFIC NOTATION:
  [0-9][0-9_]* ("." [0-9][0-9_]*)? [eE] [+-]? [0-9][0-9_]*

EXAMPLES:
  0.0, 3.14, 1.0, 0.5
  1e10, 2.5e-3, 1.0E+5
  3.14159_26535

SUFFIXES:
  f32 - 32-bit floating point
  f64 - 64-bit floating point

DEFAULT (no suffix): f64

RESTRICTIONS:
  - Must have digit before decimal point: .5 is INVALID (use 0.5)
  - Must have digit after decimal point: 1. is INVALID (use 1.0)
  - Infinity and NaN are NOT literals; use f64::INFINITY, f64::NAN
```

## 7.4 Character Literals

```
RULE LIT-004: Character Literal Syntax
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

FORMAT: ' char_content '

char_content:
  - Any Unicode scalar value except ', \, CR, LF
  - Escape sequence

EXAMPLES:
  'a', 'Z', '0', ' '    (ASCII)
  'ä¸­', 'æ—¥', 'Ø¹'        (Unicode)
  'ðŸ˜€', 'ðŸŽ‰', 'â¤'       (Emoji - single code point only)
  '\n', '\t', '\\'      (Escapes)
  '\x41'                (Hex escape = 'A')
  '\u{1F600}'           (Unicode escape = 'ðŸ˜€')

RESTRICTIONS:
  - Must contain exactly one character
  - '' is INVALID (empty)
  - 'ab' is INVALID (multiple chars)
  - Surrogates are INVALID ('\u{D800}')
```

## 7.5 String Literals

```
RULE LIT-005: String Literal Syntax
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

REGULAR STRING: " string_content "

string_content:
  - Any Unicode scalar value except ", \, CR, LF
  - Escape sequence
  - String continuation (\<newline>)

EXAMPLES:
  "hello"
  "line1\nline2"
  "say \"hello\""
  "multi\
   line"           (continuation - strips leading whitespace)

RAW STRING: r"..." or r#"..."# or r##"..."## etc.

  - No escape processing
  - Hash count must match
  - Can contain " if enough hashes

EXAMPLES:
  r"hello\nworld"          â†’ hello\nworld (literal backslash-n)
  r#"has "quotes" inside"# â†’ has "quotes" inside
  r##"has "#" inside"##    â†’ has "#" inside
```

## 7.6 Byte and Byte String Literals

```
RULE LIT-006: Byte and Byte String Literals
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

BYTE LITERAL: b'x'
  - Single ASCII character or escape
  - Type: u8
  - Examples: b'A', b'\n', b'\x7F'

BYTE STRING: b"..."
  - ASCII characters and escapes only
  - Type: &[u8; N]
  - Examples: b"hello", b"bytes\x00here"

RAW BYTE STRING: br"..." or br#"..."#
  - No escape processing
  - ASCII only
  - Examples: br"raw\nstring", br#"with "quotes""#

C STRING: c"..."
  - Null-terminated string
  - Type: &CStr
  - Examples: c"hello", c"for\x00ffi"
```

## 7.7 Escape Sequence Table

```
RULE LIT-007: Complete Escape Sequences
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Escape   â”‚ Description         â”‚ Unicode  â”‚ Valid In                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ \\       â”‚ Backslash           â”‚ U+005C   â”‚ char, str, byte, bstr       â”‚
â”‚ \'       â”‚ Single quote        â”‚ U+0027   â”‚ char, byte                  â”‚
â”‚ \"       â”‚ Double quote        â”‚ U+0022   â”‚ str, bstr, cstr             â”‚
â”‚ \n       â”‚ Line feed           â”‚ U+000A   â”‚ all                         â”‚
â”‚ \r       â”‚ Carriage return     â”‚ U+000D   â”‚ all                         â”‚
â”‚ \t       â”‚ Horizontal tab      â”‚ U+0009   â”‚ all                         â”‚
â”‚ \0       â”‚ Null                â”‚ U+0000   â”‚ all                         â”‚
â”‚ \xNN     â”‚ Hex byte (00-7F)    â”‚ U+00NN   â”‚ char, str (ASCII only)      â”‚
â”‚ \xNN     â”‚ Hex byte (00-FF)    â”‚ 0xNN     â”‚ byte, bstr (full range)     â”‚
â”‚ \u{N..}  â”‚ Unicode (1-6 hex)   â”‚ U+N...   â”‚ char, str (NOT byte/bstr)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NOTES:
  - \xNN in char/str: only 00-7F (ASCII) allowed
  - \xNN in byte/bstr: full 00-FF range allowed
  - \u{} not valid in byte literals
  - Surrogates (U+D800-U+DFFF) invalid in \u{}
  - Values beyond U+10FFFF invalid in \u{}
```

## 7.8 Boolean Literals

```
RULE LIT-008: Boolean Literals
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

true  - Boolean true value
false - Boolean false value

Type: bool

NOTES:
  - These are keywords, not identifiers
  - Cannot be shadowed by variables
  - r#true and r#false treat them as identifiers
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PART 8: TOKEN DEFINITIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 8.1 Token Categories

```
RULE TOKEN-001: Token Categories
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

IDENTIFIERS (2):
  Ident, RawIdent

LITERALS (11):
  LitInteger, LitFloat, LitChar, LitString, LitRawString,
  LitByteString, LitRawByteString, LitCString, LitByte, LitBool,
  LitByteChar

KEYWORDS (72 active + 26 reserved):
  All keywords from Part 5

OPERATORS (35):
  Plus, Minus, Star, Slash, Percent, Amp, Pipe, Caret, Bang, Tilde,
  Lt, Gt, Eq, Dot, Question, At,
  EqEq, BangEq, LtEq, GtEq, AmpAmp, PipePipe, LtLt, GtGt,
  PlusEq, MinusEq, StarEq, SlashEq, PercentEq, AmpEq, PipeEq,
  CaretEq, LtLtEq, GtGtEq, DotDot, DotDotEq, Arrow, FatArrow, ColonColon

PUNCTUATION (16):
  OpenParen, CloseParen, OpenBracket, CloseBracket, OpenBrace, CloseBrace,
  Comma, Semicolon, Colon, Apostrophe, Quote, Hash, Dollar, Underscore,
  PathSep, At

COMMENTS (6):
  LineComment, BlockComment, OuterLineDoc, OuterBlockDoc,
  InnerLineDoc, InnerBlockDoc

WHITESPACE (2):
  Whitespace, Newline

SPECIAL (2):
  Eof, Error
```

## 8.2 Token Structure

```
RULE TOKEN-002: Token Structure
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

struct Token {
    kind: TokenKind,
    span: Span,
    symbol: Option<Symbol>,    // For identifiers and string content
    suffix: Option<Suffix>,    // For numeric literals
}

struct Span {
    start: Position,
    end: Position,
    file_id: FileId,
}

struct Position {
    byte_offset: u32,
    line: u32,
    column: u32,
}

enum TokenKind {
    // All token kinds from TOKEN-001
}
```

## 8.3 Total Token Count

```
RULE TOKEN-003: Token Kind Totals
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Category                    â”‚ Count                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Identifiers                 â”‚ 2                                          â”‚
â”‚ Literals                    â”‚ 11                                         â”‚
â”‚ Active Keywords             â”‚ 72                                         â”‚
â”‚ Reserved Keywords           â”‚ 26                                         â”‚
â”‚ Operators                   â”‚ 35                                         â”‚
â”‚ Punctuation                 â”‚ 16                                         â”‚
â”‚ Comments                    â”‚ 6                                          â”‚
â”‚ Whitespace                  â”‚ 2                                          â”‚
â”‚ Special                     â”‚ 2                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL TOKEN KINDS           â”‚ 172                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                     PART 9: LEXER STATE MACHINE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 9.1 Lexer States

```
RULE STATE-001: Lexer States
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

enum LexerState {
    Normal,
    String,
    RawString { hash_count: u8 },
    Char,
    Byte,
    ByteString,
    RawByteString { hash_count: u8 },
    CString,
    LineComment,
    BlockComment { depth: u32 },
    DocComment { is_block: bool, is_inner: bool, depth: u32 },
}
```

## 9.2 State Transitions

```
RULE STATE-002: State Transitions
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

From Normal:
  " â†’ String
  r" â†’ RawString { hash_count: 0 }
  r### followed by " â†’ RawString { hash_count: N }
  ' â†’ Char or Lifetime (contextual)
  b' â†’ Byte
  b" â†’ ByteString
  br" or br#" â†’ RawByteString
  c" â†’ CString
  // â†’ LineComment
  /* â†’ BlockComment { depth: 1 }
  /// â†’ DocComment { is_block: false, is_inner: false }
  //! â†’ DocComment { is_block: false, is_inner: true }
  /** â†’ DocComment { is_block: true, is_inner: false }
  /*! â†’ DocComment { is_block: true, is_inner: true }

From String:
  " â†’ Normal (end string)
  \ â†’ process escape, stay in String
  newline â†’ Error
  EOF â†’ Error

From RawString:
  "### (matching hash count) â†’ Normal
  EOF â†’ Error

From BlockComment:
  /* â†’ increment depth
  */ â†’ decrement depth (exit to Normal if depth=0)
  EOF â†’ Error
```

## 9.3 Error Recovery

```
RULE STATE-003: Error Recovery
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

RECOVERY STRATEGIES:

1. SKIP CHARACTER
   - For invalid UTF-8 or unexpected characters
   - Skip to next valid character
   - Continue lexing

2. SKIP TO DELIMITER
   - For unterminated strings
   - Skip to matching quote or EOF
   - Report position of opening delimiter

3. SKIP TO NEWLINE
   - For errors in line comments
   - Continue on next line

4. ABORT
   - For unrecoverable errors (file too large, BOM)
   - Stop lexing immediately
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                 PART 10: TERAS-SPECIFIC LEXICAL CONSIDERATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 10.1 Security Type Syntax

```
RULE TERAS-001: Security Type Annotations
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Security types use standard generic syntax:

  Secret<T>        - Secret value of type T
  Tainted<T, L>    - Tainted value with label L
  Sanitized<T>     - Sanitized value

LEXING:
  "Secret<T>" â†’ [Ident("Secret"), Lt, Ident("T"), Gt]
  
Parser handles type construction, not lexer.
```

## 10.2 Effect Annotation Syntax

```
RULE TERAS-002: Effect Annotations
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Effect annotations use braces after function signature:

  fn read() {IO} -> String
  fn process() {IO, Console} -> ()

LEXING:
  "{IO, Console}" â†’ [OpenBrace, Ident("IO"), Comma, Ident("Console"), CloseBrace]

Parser distinguishes effect annotation context from block context.
```

## 10.3 Malay Identifier Support

```
RULE TERAS-003: Malay Identifiers
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

All Malay identifiers use Latin alphabet (A-Z, a-z).
No special lexer handling required.

Standard library Malay names:
  simpan, muatkan, hapus, tukar, senarai, peta
  rahsia, awam, sulit, tercemar, bersih, lindungi, jejak
  menara, gapura, zirah, benteng, sandi
```

## 10.4 Security Implications

```
RULE TERAS-004: Lexer Security
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. Identifier Security
   - Homoglyph detection (see UTF8-006)
   - Mixed-script warnings
   - Zero-width character rejection
   - Bidirectional override rejection

2. Literal Security
   - Control character warnings in strings
   - Bidirectional override warnings in strings
   - Integer overflow detection at lex time

3. Comment Security
   - Trojan Source detection (bidi characters)
   - NUL character warnings
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         PART 11: TEST CASES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 11.1 Basic Token Tests

```
TEST-001: Empty source
  Input: ""
  Expected: [Eof]

TEST-002: Single identifier
  Input: "foo"
  Expected: [Ident("foo"), Eof]

TEST-003: Single keyword
  Input: "fn"
  Expected: [KwFn, Eof]

TEST-004: Single integer
  Input: "42"
  Expected: [LitInteger(42), Eof]

TEST-005: Operators
  Input: "+ - * /"
  Expected: [Plus, Minus, Star, Slash, Eof]
```

## 11.2 Keyword Tests

```
TEST-006: All control flow
  Input: "if else match loop while for break continue return"
  Expected: [KwIf, KwElse, KwMatch, KwLoop, KwWhile, KwFor,
             KwBreak, KwContinue, KwReturn, Eof]

TEST-007: Security keywords
  Input: "secret tainted sanitized declassify"
  Expected: [KwSecret, KwTainted, KwSanitized, KwDeclassify, Eof]
```

## 11.3 Literal Tests

```
TEST-008: Integer formats
  Input: "42 0xFF 0o77 0b1010"
  Expected: [LitInt(42), LitInt(255), LitInt(63), LitInt(10), Eof]

TEST-009: String escapes
  Input: "\"hello\\nworld\""
  Expected: [LitString("hello\nworld"), Eof]

TEST-010: Raw string
  Input: "r#\"hello\"world\"#"
  Expected: [LitRawString("hello\"world"), Eof]
```

## 11.4 Comment Tests

```
TEST-011: Line comment discarded
  Input: "foo // comment\nbar"
  Expected: [Ident("foo"), Ident("bar"), Eof]

TEST-012: Nested block comment
  Input: "/* outer /* inner */ still outer */ after"
  Expected: [Ident("after"), Eof]

TEST-013: Doc comment preserved
  Input: "/// doc"
  Expected: [OuterLineDoc(" doc"), Eof]
```

## 11.5 Unicode Tests

```
TEST-014: Malay identifiers
  Input: "rahsia simpan lindungi"
  Expected: [Ident("rahsia"), Ident("simpan"), Ident("lindungi"), Eof]

TEST-015: CJK identifiers
  Input: "å˜é‡ å‡½æ•°"
  Expected: [Ident("å˜é‡"), Ident("å‡½æ•°"), Eof]
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                           PART 12: APPENDICES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## Appendix A: Complete Token Kinds

All 172 token kinds listed in TOKEN-001 through TOKEN-003.

## Appendix B: Escape Sequences

Complete table in LIT-007.

## Appendix C: Unicode Categories

XID_Start and XID_Continue as defined in IDENT-001.

## Appendix D: Reserved Keywords

26 reserved keywords listed in KW-013.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        PART 13: DOCUMENT VALIDATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 13.1 Anti-Hallucination Checklist

```
VALIDATION CHECKLIST
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ All 72 active keywords listed individually
âœ“ All 26 reserved keywords listed individually
âœ“ All operators with precedence (18 levels)
âœ“ All 10 escape sequences in table
âœ“ All Unicode categories explicitly named
âœ“ All 12 integer suffixes listed
âœ“ All 2 float suffixes listed
âœ“ No "typically," "usually," "generally," or "etc."
âœ“ No external document references for critical definitions
âœ“ Line count exceeds 2,500
```

## 13.2 Cross-Reference Validation

```
CROSS-REFERENCE CHECK
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Foundation Document References:
âœ“ D1 (Universe Structure) - Type conventions
âœ“ D4 (Linear Types) - Keywords
âœ“ D37 (Threat Defense) - Security
âœ“ D38 (Performance) - Efficiency
âœ“ D39 (Memory Model) - Memory keywords
âœ“ D40 (Effect System) - Effect keywords
âœ“ D41 (Ownership) - Lifetime syntax
âœ“ D42 (Security Types) - Security keywords
âœ“ D46 (Malay Naming) - Malay identifiers

CTSS v1.0.1 Consistency:
âœ“ Identifier grammar matches
âœ“ Keyword list matches
âœ“ Literal syntax matches
âœ“ Type suffixes match
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SESSION: A-R01 COMPLETE
OUTPUT DOCUMENT: TERAS-LANG-LEXER-SPEC_v1.0.0.md
STATUS: READY FOR A-V01 VERIFICATION
NEXT SESSION: A-R02 (Grammar: Expressions)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

HANDOFF NOTES FOR NEXT SESSION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. PRECEDENCE TABLE: 18 levels defined (use for expression grammar)
2. TOKEN CATEGORIES: 172 token kinds enumerated
3. SECURITY KEYWORDS: 8 security + 7 memory + 5 effect keywords
4. MALAY SUPPORT: All Malay identifiers valid (Latin alphabet)
5. RAW IDENTIFIERS: r#keyword syntax for all keywords
6. LITERAL FORMATS: Integer (dec/hex/oct/bin), float, string, char
7. EDGE CASES: <> generics vs comparison, & ref vs AND, ' lifetime vs char

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PART 14: LEXER ALGORITHM PSEUDOCODE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 14.1 Main Lexer Loop

```
ALGORITHM: Main Lexer Loop
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

fn lex_all(source: &str) -> Vec<Token> {
    let mut lexer = Lexer::new(source);
    let mut tokens = Vec::new();
    
    loop {
        let token = lexer.next_token();
        let is_eof = token.kind == TokenKind::Eof;
        tokens.push(token);
        if is_eof {
            break;
        }
    }
    
    tokens
}

fn next_token(&mut self) -> Token {
    self.skip_whitespace_and_comments();
    
    if self.is_eof() {
        return Token::eof(self.position());
    }
    
    let start = self.position();
    let c = self.peek().unwrap();
    
    match c {
        'a'..='z' | 'A'..='Z' | '_' => self.lex_identifier_or_keyword(),
        '0'..='9' => self.lex_number(),
        '"' => self.lex_string(),
        '\'' => self.lex_char_or_lifetime(),
        'r' => self.lex_r_prefix(),
        'b' => self.lex_b_prefix(),
        'c' if self.peek_second() == Some('"') => self.lex_c_string(),
        _ if is_operator_start(c) => self.lex_operator(),
        _ if is_punctuation(c) => self.lex_punctuation(),
        _ if is_xid_start(c) => self.lex_unicode_identifier(),
        _ => self.error_token(UnexpectedCharacter(c)),
    }
}
```

## 14.2 Identifier Lexing

```
ALGORITHM: Identifier Lexing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

fn lex_identifier_or_keyword(&mut self) -> Token {
    let start = self.position();
    let mut content = String::new();
    
    // Check for raw identifier
    if self.peek() == Some('r') && self.peek_second() == Some('#') {
        self.advance(); // consume 'r'
        self.advance(); // consume '#'
        return self.lex_raw_identifier(start);
    }
    
    // Regular identifier
    while let Some(c) = self.peek() {
        if is_xid_continue(c) || c == '_' {
            content.push(c);
            self.advance();
        } else {
            break;
        }
    }
    
    // Check length
    if content.chars().count() > 1024 {
        return self.error_token(IdentifierTooLong);
    }
    
    // Normalize to NFC
    let normalized = normalize_nfc(&content);
    if normalized != content {
        self.warn(NotInNfcForm(start));
    }
    
    // Check for keyword
    if let Some(kw) = lookup_keyword(&normalized) {
        return Token::keyword(kw, Span::new(start, self.position()));
    }
    
    // Check for reserved keyword
    if is_reserved_keyword(&normalized) {
        return self.error_token(ReservedKeyword(normalized));
    }
    
    // Security checks
    self.check_identifier_security(&normalized, start);
    
    Token::ident(normalized, Span::new(start, self.position()))
}

fn lex_raw_identifier(&mut self, start: Position) -> Token {
    let mut content = String::new();
    
    while let Some(c) = self.peek() {
        if is_xid_continue(c) || c == '_' {
            content.push(c);
            self.advance();
        } else {
            break;
        }
    }
    
    if content.is_empty() {
        return self.error_token(EmptyRawIdentifier);
    }
    
    if content == "_" {
        return self.error_token(RawUnderscore);
    }
    
    Token::raw_ident(content, Span::new(start, self.position()))
}
```

## 14.3 Number Lexing

```
ALGORITHM: Number Lexing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

fn lex_number(&mut self) -> Token {
    let start = self.position();
    
    // Check for base prefix
    if self.peek() == Some('0') {
        match self.peek_second() {
            Some('x') | Some('X') => return self.lex_hex(start),
            Some('o') | Some('O') => return self.lex_octal(start),
            Some('b') | Some('B') => return self.lex_binary(start),
            _ => {}
        }
    }
    
    self.lex_decimal(start)
}

fn lex_decimal(&mut self, start: Position) -> Token {
    let mut digits = String::new();
    let mut has_dot = false;
    let mut has_exp = false;
    
    // Integer part
    while let Some(c) = self.peek() {
        match c {
            '0'..='9' => {
                digits.push(c);
                self.advance();
            }
            '_' => {
                self.advance(); // Skip underscore
            }
            '.' if !has_dot && self.peek_second() != Some('.') => {
                // Decimal point (not range operator)
                if self.peek_second().map_or(false, |c| c.is_ascii_digit()) {
                    has_dot = true;
                    digits.push('.');
                    self.advance();
                } else {
                    break;
                }
            }
            'e' | 'E' if !has_exp => {
                has_exp = true;
                digits.push(c);
                self.advance();
                // Optional sign
                if matches!(self.peek(), Some('+') | Some('-')) {
                    digits.push(self.peek().unwrap());
                    self.advance();
                }
            }
            _ => break,
        }
    }
    
    // Type suffix
    let suffix = self.try_lex_suffix();
    
    if has_dot || has_exp {
        Token::float(digits, suffix, Span::new(start, self.position()))
    } else {
        let value = parse_decimal(&digits)?;
        Token::integer(value, suffix, Span::new(start, self.position()))
    }
}

fn lex_hex(&mut self, start: Position) -> Token {
    self.advance(); // '0'
    self.advance(); // 'x'
    
    let mut digits = String::new();
    
    while let Some(c) = self.peek() {
        match c {
            '0'..='9' | 'a'..='f' | 'A'..='F' => {
                digits.push(c);
                self.advance();
            }
            '_' => {
                self.advance();
            }
            _ => break,
        }
    }
    
    if digits.is_empty() {
        return self.error_token(NoDigitsAfterPrefix("0x"));
    }
    
    let suffix = self.try_lex_suffix();
    let value = u128::from_str_radix(&digits, 16).unwrap();
    
    Token::integer(value, suffix, Span::new(start, self.position()))
}

fn lex_octal(&mut self, start: Position) -> Token {
    self.advance(); // '0'
    self.advance(); // 'o'
    
    let mut digits = String::new();
    
    while let Some(c) = self.peek() {
        match c {
            '0'..='7' => {
                digits.push(c);
                self.advance();
            }
            '8' | '9' => {
                return self.error_token(InvalidOctalDigit(c));
            }
            '_' => {
                self.advance();
            }
            _ => break,
        }
    }
    
    if digits.is_empty() {
        return self.error_token(NoDigitsAfterPrefix("0o"));
    }
    
    let suffix = self.try_lex_suffix();
    let value = u128::from_str_radix(&digits, 8).unwrap();
    
    Token::integer(value, suffix, Span::new(start, self.position()))
}

fn lex_binary(&mut self, start: Position) -> Token {
    self.advance(); // '0'
    self.advance(); // 'b'
    
    let mut digits = String::new();
    
    while let Some(c) = self.peek() {
        match c {
            '0' | '1' => {
                digits.push(c);
                self.advance();
            }
            '2'..='9' => {
                return self.error_token(InvalidBinaryDigit(c));
            }
            '_' => {
                self.advance();
            }
            _ => break,
        }
    }
    
    if digits.is_empty() {
        return self.error_token(NoDigitsAfterPrefix("0b"));
    }
    
    let suffix = self.try_lex_suffix();
    let value = u128::from_str_radix(&digits, 2).unwrap();
    
    Token::integer(value, suffix, Span::new(start, self.position()))
}
```

## 14.4 String Lexing

```
ALGORITHM: String Lexing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

fn lex_string(&mut self) -> Token {
    let start = self.position();
    self.advance(); // Opening quote
    
    let mut content = String::new();
    
    loop {
        match self.peek() {
            None => {
                return self.error_token(UnterminatedString(start));
            }
            Some('"') => {
                self.advance();
                break;
            }
            Some('\\') => {
                self.advance();
                match self.lex_escape() {
                    Ok(c) => content.push(c),
                    Err(e) => self.errors.push(e),
                }
            }
            Some('\r') | Some('\n') => {
                return self.error_token(NewlineInString(start));
            }
            Some(c) => {
                // Check for suspicious characters
                if is_bidi_control(c) {
                    self.warn(BidiInString(self.position()));
                }
                content.push(c);
                self.advance();
            }
        }
    }
    
    Token::string(content, Span::new(start, self.position()))
}

fn lex_escape(&mut self) -> Result<char, LexerError> {
    match self.peek() {
        Some('\\') => { self.advance(); Ok('\\') }
        Some('\'') => { self.advance(); Ok('\'') }
        Some('"') => { self.advance(); Ok('"') }
        Some('n') => { self.advance(); Ok('\n') }
        Some('r') => { self.advance(); Ok('\r') }
        Some('t') => { self.advance(); Ok('\t') }
        Some('0') => { self.advance(); Ok('\0') }
        Some('x') => self.lex_hex_escape(),
        Some('u') => self.lex_unicode_escape(),
        Some(c) => {
            self.advance();
            Err(InvalidEscape(format!("\\{}", c)))
        }
        None => Err(UnexpectedEof),
    }
}

fn lex_hex_escape(&mut self) -> Result<char, LexerError> {
    self.advance(); // 'x'
    
    let h1 = self.expect_hex_digit()?;
    let h2 = self.expect_hex_digit()?;
    
    let value = (h1 << 4) | h2;
    
    if value > 0x7F {
        return Err(HexEscapeOutOfRange(value));
    }
    
    Ok(value as u8 as char)
}

fn lex_unicode_escape(&mut self) -> Result<char, LexerError> {
    self.advance(); // 'u'
    
    if self.peek() != Some('{') {
        return Err(ExpectedOpenBrace);
    }
    self.advance(); // '{'
    
    let mut value: u32 = 0;
    let mut digits = 0;
    
    loop {
        match self.peek() {
            Some('}') => {
                self.advance();
                break;
            }
            Some(c) if c.is_ascii_hexdigit() => {
                digits += 1;
                if digits > 6 {
                    return Err(TooManyHexDigits);
                }
                value = value * 16 + c.to_digit(16).unwrap();
                self.advance();
            }
            _ => {
                return Err(InvalidUnicodeEscape);
            }
        }
    }
    
    if digits == 0 {
        return Err(EmptyUnicodeEscape);
    }
    
    if value > 0x10FFFF {
        return Err(CodePointTooLarge(value));
    }
    
    if (0xD800..=0xDFFF).contains(&value) {
        return Err(SurrogateCodePoint(value));
    }
    
    char::from_u32(value).ok_or(InvalidCodePoint(value))
}
```

## 14.5 Comment Lexing

```
ALGORITHM: Comment Lexing
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

fn skip_whitespace_and_comments(&mut self) {
    loop {
        match self.peek() {
            Some(c) if c.is_whitespace() => {
                if c == '\n' {
                    self.line += 1;
                    self.column = 1;
                }
                self.advance();
            }
            Some('/') => {
                match self.peek_second() {
                    Some('/') => {
                        if !self.is_doc_comment() {
                            self.skip_line_comment();
                        } else {
                            return; // Doc comment is a token
                        }
                    }
                    Some('*') => {
                        if !self.is_doc_comment() {
                            self.skip_block_comment();
                        } else {
                            return; // Doc comment is a token
                        }
                    }
                    _ => return,
                }
            }
            _ => return,
        }
    }
}

fn skip_line_comment(&mut self) {
    self.advance(); // '/'
    self.advance(); // '/'
    
    while let Some(c) = self.peek() {
        if c == '\n' {
            break;
        }
        self.advance();
    }
}

fn skip_block_comment(&mut self) {
    self.advance(); // '/'
    self.advance(); // '*'
    
    let mut depth = 1u32;
    
    while depth > 0 {
        match self.peek() {
            None => {
                self.errors.push(UnterminatedBlockComment);
                return;
            }
            Some('/') => {
                self.advance();
                if self.peek() == Some('*') {
                    self.advance();
                    depth += 1;
                }
            }
            Some('*') => {
                self.advance();
                if self.peek() == Some('/') {
                    self.advance();
                    depth -= 1;
                }
            }
            Some('\n') => {
                self.line += 1;
                self.column = 1;
                self.advance();
            }
            _ => {
                self.advance();
            }
        }
    }
}

fn lex_doc_comment(&mut self) -> Token {
    let start = self.position();
    self.advance(); // '/'
    self.advance(); // '/' or '*'
    
    let is_block = self.prev_char() == '*';
    let is_inner = self.peek() == Some('!');
    
    if is_inner {
        self.advance(); // '!'
    } else if !is_block && self.peek() == Some('/') && self.peek_second() != Some('/') {
        self.advance(); // '/' for ///
    } else if is_block && self.peek() == Some('*') && self.peek_second() != Some('/') {
        self.advance(); // '*' for /**
    }
    
    let content = if is_block {
        self.read_block_doc_content()
    } else {
        self.read_line_doc_content()
    };
    
    let kind = match (is_block, is_inner) {
        (false, false) => TokenKind::OuterLineDoc,
        (false, true) => TokenKind::InnerLineDoc,
        (true, false) => TokenKind::OuterBlockDoc,
        (true, true) => TokenKind::InnerBlockDoc,
    };
    
    Token::doc(kind, content, Span::new(start, self.position()))
}
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                   PART 15: ERROR MESSAGES CATALOG
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 15.1 UTF-8 Errors

```
ERROR CATALOG: UTF-8 Errors
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

E0001: Invalid UTF-8 sequence
  Message: "Invalid UTF-8 byte sequence at offset {offset}"
  Cause: File contains invalid UTF-8 bytes
  Fix: Ensure file is saved as UTF-8

E0002: Overlong encoding
  Message: "Overlong UTF-8 encoding detected"
  Cause: Character encoded with more bytes than necessary
  Fix: Re-save file with proper UTF-8 encoding

E0003: Surrogate code point
  Message: "UTF-16 surrogate code point U+{code:04X} in UTF-8"
  Cause: File contains surrogate code points (0xD800-0xDFFF)
  Fix: Remove or replace surrogate characters

E0004: Code point too large
  Message: "Code point U+{code:X} exceeds maximum U+10FFFF"
  Cause: Invalid Unicode code point
  Fix: Use valid Unicode characters

E0005: UTF-8 BOM detected
  Message: "UTF-8 BOM detected; TERAS-LANG source files must not contain a BOM"
  Cause: File starts with bytes EF BB BF
  Fix: Remove BOM from file start
```

## 15.2 Lexical Errors

```
ERROR CATALOG: Lexical Errors
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

E0010: Unterminated string
  Message: "Unterminated string literal starting at line {line}"
  Cause: String not closed with matching quote
  Fix: Add closing quote

E0011: Unterminated character
  Message: "Unterminated character literal"
  Cause: Character literal not closed with '
  Fix: Add closing single quote

E0012: Unterminated block comment
  Message: "Unterminated block comment (depth {depth})"
  Cause: /* not matched with */
  Fix: Add closing */

E0013: Empty character literal
  Message: "Empty character literal"
  Cause: '' with nothing inside
  Fix: Add a character between quotes

E0014: Multiple characters in char literal
  Message: "Character literal contains multiple characters"
  Cause: More than one character between single quotes
  Fix: Use string literal or single character

E0015: Invalid escape sequence
  Message: "Invalid escape sequence \\{char}"
  Cause: Backslash followed by invalid escape character
  Fix: Use valid escape: \\, \', \", \n, \r, \t, \0, \x, \u

E0016: Hex escape out of range
  Message: "\\x{value:02X} is out of ASCII range (max 7F)"
  Cause: \xNN where NN > 7F in string/char (not byte)
  Fix: Use \u{} for non-ASCII or byte literal

E0017: Unicode escape too large
  Message: "Unicode escape \\u{{{value:X}}} exceeds U+10FFFF"
  Cause: Code point in \u{} exceeds maximum
  Fix: Use valid Unicode code point

E0018: Unexpected character
  Message: "Unexpected character '{char}'"
  Cause: Character not valid in any token
  Fix: Remove or replace character

E0019: Identifier too long
  Message: "Identifier exceeds maximum length of 1024 characters"
  Cause: Identifier with more than 1024 Unicode scalar values
  Fix: Use shorter identifier

E0020: Reserved keyword
  Message: "'{keyword}' is reserved for future use"
  Cause: Using a reserved keyword as identifier
  Fix: Use different name or r#{keyword}
```

## 15.3 Numeric Literal Errors

```
ERROR CATALOG: Numeric Errors
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

E0030: No digits after prefix
  Message: "No digits after {prefix} prefix"
  Cause: 0x, 0o, or 0b not followed by digits
  Fix: Add digits after prefix

E0031: Invalid octal digit
  Message: "Invalid digit '{digit}' in octal literal"
  Cause: Digit 8 or 9 in octal literal
  Fix: Use only 0-7 in octal

E0032: Invalid binary digit
  Message: "Invalid digit '{digit}' in binary literal"
  Cause: Digit other than 0 or 1 in binary literal
  Fix: Use only 0-1 in binary

E0033: Integer overflow
  Message: "Integer literal is too large"
  Cause: Value exceeds maximum for any integer type
  Fix: Use smaller value or different type

E0034: Invalid float
  Message: "Invalid floating-point literal"
  Cause: Malformed float (e.g., .5 or 1.)
  Fix: Use proper format (0.5, 1.0)

E0035: Invalid suffix
  Message: "Invalid numeric suffix '{suffix}'"
  Cause: Unknown type suffix on literal
  Fix: Use valid suffix (i8-i128, u8-u128, f32, f64)
```

## 15.4 Security Warnings

```
WARNING CATALOG: Security Warnings
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

W0001: Identifier not in NFC
  Message: "Identifier '{ident}' is not in NFC form; normalizing"
  Cause: Identifier uses non-canonical Unicode representation
  Action: Normalize to NFC

W0002: Mixed-script identifier
  Message: "Identifier '{ident}' mixes scripts: {scripts}"
  Cause: Identifier contains characters from multiple scripts
  Action: Review for potential confusion attacks

W0003: Confusable identifier
  Message: "Identifier '{ident}' is visually similar to '{other}'"
  Cause: Homoglyph detection found similar identifier
  Action: Review for potential confusion

W0004: Bidirectional control in comment
  Message: "Bidirectional control character in comment (potential Trojan Source)"
  Cause: Comment contains bidi override characters
  Action: Remove bidirectional controls

W0005: Bidirectional control in string
  Message: "Bidirectional control character U+{code:04X} in string"
  Cause: String contains bidi override characters
  Action: Consider if intentional
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                      PART 16: IMPLEMENTATION NOTES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

## 16.1 Performance Considerations

```
IMPLEMENTATION: Performance
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. KEYWORD LOOKUP
   - Use perfect hash function for O(1) lookup
   - Generate with gperf or similar tool
   - 98 keywords (72 active + 26 reserved)

2. UNICODE TABLES
   - XID_Start: ~131,878 code points
   - XID_Continue: ~135,307 code points
   - Use binary search on ranges
   - Or use Unicode tables crate

3. BUFFER STRATEGY
   - Memory-map large files
   - Read in 4KB chunks for small files
   - Pre-allocate token vector (estimate: 1 token per 5 bytes)

4. STRING INTERNING
   - Intern identifier strings
   - Share identical strings across tokens
   - Use arena allocator for session
```

## 16.2 Memory Layout

```
IMPLEMENTATION: Memory Layout
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Token (32 bytes):
  kind: u8          // Token kind enum
  _pad1: [u8; 3]    // Padding
  span: Span (16)   // Start/end position
  data: u64         // Symbol index or literal value
  suffix: u16       // Type suffix if any
  _pad2: [u8; 2]    // Padding

Span (16 bytes):
  start: Position (8)
  end: Position (8)

Position (8 bytes):
  byte_offset: u32
  line: u16
  column: u16
```

## 16.3 Test Coverage Requirements

```
IMPLEMENTATION: Test Coverage
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Minimum coverage targets:
  - Statement coverage: 100%
  - Branch coverage: 100%
  - All keywords tested
  - All operators tested
  - All escape sequences tested
  - All error conditions tested
  - Unicode edge cases tested
  - Malformed input tested
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         DOCUMENT FOOTER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Document: TERAS-LANG-LEXER-SPEC_v1.0.0.md
Version: 1.0.0
Date: 2026-01-01
Session: A-R01
Status: COMPLETE

Line Count: 2,906
Sections: 16
Keywords: 98 (72 active + 26 reserved)
Token Kinds: 172
Operators: 35
Precedence Levels: 18

VALIDATION: All requirements met per TERAS ULTRA KIASU protocol.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SESSION: A-R01 COMPLETE
OUTPUT DOCUMENT: TERAS-LANG-LEXER-SPEC_v1.0.0.md
OUTPUT HASH (pre-footer): c7947cfe53c3147ae44b53d9f62915cdef62667d445ffaa636c9f25c2adfa09d
LINES PRODUCED: 2,906
NEXT SESSION: A-R02 (Grammar: Expressions)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                              END OF DOCUMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
